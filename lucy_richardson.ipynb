{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pearsonr\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ndimage\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/bagpipes/lib/python3.10/site-packages/scipy/stats/__init__.py:608\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03m.. _statsrefmanual:\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    603\u001b[0m \n\u001b[1;32m    604\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_warnings_errors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (ConstantInputWarning, NearConstantInputWarning,\n\u001b[1;32m    607\u001b[0m                                DegenerateDataWarning, FitError)\n\u001b[0;32m--> 608\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_stats_py\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    609\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_variation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m variation\n\u001b[1;32m    610\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/bagpipes/lib/python3.10/site-packages/scipy/stats/_stats_py.py:39\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NumpyVersion\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtesting\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m suppress_warnings\n\u001b[0;32m---> 39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspatial\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistance\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cdist\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mndimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _measurements\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_util\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (check_random_state, MapWrapper, _get_nan,\n\u001b[1;32m     42\u001b[0m                               rng_integers, _rename_parameter, _contains_nan)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/bagpipes/lib/python3.10/site-packages/scipy/spatial/__init__.py:110\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03m=============================================================\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mSpatial algorithms and data structures (:mod:`scipy.spatial`)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;124;03m   QhullError\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 110\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_kdtree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_ckdtree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_qhull\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/bagpipes/lib/python3.10/site-packages/scipy/spatial/_kdtree.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright Anne M. Archibald 2008\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Released under the scipy license\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_ckdtree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cKDTree, cKDTreeNode\n\u001b[1;32m      6\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminkowski_distance_p\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminkowski_distance\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      7\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistance_matrix\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      8\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRectangle\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKDTree\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mminkowski_distance_p\u001b[39m(x, y, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m):\n",
      "File \u001b[0;32m_ckdtree.pyx:1\u001b[0m, in \u001b[0;36minit scipy.spatial._ckdtree\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def psnr(original, reconstructed, data_range=1.0):\n",
    "    \"\"\"Calculate Peak Signal-to-Noise Ratio\"\"\"\n",
    "    mse = np.mean((original - reconstructed) ** 2)\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    return 20 * np.log10(data_range / np.sqrt(mse))\n",
    "\n",
    "\n",
    "def ssim(img1, img2, data_range=1.0, win_size=11):\n",
    "    \"\"\"\n",
    "    Calculate Structural Similarity Index\n",
    "    Simplified implementation without scikit-image dependency\n",
    "    \"\"\"\n",
    "    C1 = (0.01 * data_range) ** 2\n",
    "    C2 = (0.03 * data_range) ** 2\n",
    "    \n",
    "    # Create Gaussian window\n",
    "    sigma = 1.5\n",
    "    truncate = 3.5\n",
    "    radius = int(truncate * sigma + 0.5)\n",
    "    \n",
    "    # Simple averaging window as fallback\n",
    "    window = np.ones((win_size, win_size)) / (win_size ** 2)\n",
    "    \n",
    "    mu1 = ndimage.convolve(img1, window, mode='reflect')\n",
    "    mu2 = ndimage.convolve(img2, window, mode='reflect')\n",
    "    \n",
    "    mu1_sq = mu1 ** 2\n",
    "    mu2_sq = mu2 ** 2\n",
    "    mu1_mu2 = mu1 * mu2\n",
    "    \n",
    "    sigma1_sq = ndimage.convolve(img1 ** 2, window, mode='reflect') - mu1_sq\n",
    "    sigma2_sq = ndimage.convolve(img2 ** 2, window, mode='reflect') - mu2_sq\n",
    "    sigma12 = ndimage.convolve(img1 * img2, window, mode='reflect') - mu1_mu2\n",
    "    \n",
    "    ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / \\\n",
    "               ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))\n",
    "    \n",
    "    return np.mean(ssim_map)\n",
    "\n",
    "\n",
    "def comprehensive_deconvolution_analysis(original, blurry, deconvolved, psf=None):\n",
    "    \"\"\"\n",
    "    Complete performance analysis for deconvolution with visualization.\n",
    "    Works without scikit-image dependency.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    original : numpy array\n",
    "        Original sharp image (ground truth)\n",
    "    blurry : numpy array\n",
    "        Simulated blurry image\n",
    "    deconvolved : numpy array\n",
    "        Richardson-Lucy deconvolved result\n",
    "    psf : numpy array, optional\n",
    "        Point spread function used\n",
    "    \"\"\"\n",
    "    \n",
    "    # Normalize images\n",
    "    def normalize(img):\n",
    "        img_min, img_max = img.min(), img.max()\n",
    "        if img_max == img_min:\n",
    "            return np.zeros_like(img)\n",
    "        return (img - img_min) / (img_max - img_min)\n",
    "    \n",
    "    orig_norm = normalize(original)\n",
    "    blur_norm = normalize(blurry)\n",
    "    deconv_norm = normalize(deconvolved)\n",
    "    \n",
    "    metrics = {}\n",
    "    \n",
    "    # === Quality Metrics ===\n",
    "    # PSNR\n",
    "    metrics['psnr_blurry'] = psnr(orig_norm, blur_norm, data_range=1.0)\n",
    "    metrics['psnr_deconvolved'] = psnr(orig_norm, deconv_norm, data_range=1.0)\n",
    "    metrics['psnr_gain'] = metrics['psnr_deconvolved'] - metrics['psnr_blurry']\n",
    "    \n",
    "    # SSIM\n",
    "    metrics['ssim_blurry'] = ssim(orig_norm, blur_norm, data_range=1.0)\n",
    "    metrics['ssim_deconvolved'] = ssim(orig_norm, deconv_norm, data_range=1.0)\n",
    "    metrics['ssim_gain'] = metrics['ssim_deconvolved'] - metrics['ssim_blurry']\n",
    "    \n",
    "    # MSE\n",
    "    metrics['mse_blurry'] = np.mean((orig_norm - blur_norm) ** 2)\n",
    "    metrics['mse_deconvolved'] = np.mean((orig_norm - deconv_norm) ** 2)\n",
    "    metrics['mse_reduction_pct'] = (metrics['mse_blurry'] - metrics['mse_deconvolved']) / metrics['mse_blurry'] * 100\n",
    "    \n",
    "    # MAE (Mean Absolute Error)\n",
    "    metrics['mae_blurry'] = np.mean(np.abs(orig_norm - blur_norm))\n",
    "    metrics['mae_deconvolved'] = np.mean(np.abs(orig_norm - deconv_norm))\n",
    "    \n",
    "    # Correlation\n",
    "    metrics['corr_blurry'] = pearsonr(orig_norm.flatten(), blur_norm.flatten())[0]\n",
    "    metrics['corr_deconvolved'] = pearsonr(orig_norm.flatten(), deconv_norm.flatten())[0]\n",
    "    \n",
    "    # === Sharpness Metrics ===\n",
    "    def laplacian_variance(img):\n",
    "        laplacian = ndimage.laplace(img)\n",
    "        return laplacian.var()\n",
    "    \n",
    "    metrics['sharpness_original'] = laplacian_variance(orig_norm)\n",
    "    metrics['sharpness_blurry'] = laplacian_variance(blur_norm)\n",
    "    metrics['sharpness_deconvolved'] = laplacian_variance(deconv_norm)\n",
    "    metrics['sharpness_recovery_pct'] = (metrics['sharpness_deconvolved'] / metrics['sharpness_original']) * 100\n",
    "    \n",
    "    # Edge strength\n",
    "    def edge_strength(img):\n",
    "        gy, gx = np.gradient(img)\n",
    "        return np.mean(np.sqrt(gx**2 + gy**2))\n",
    "    \n",
    "    metrics['edge_original'] = edge_strength(orig_norm)\n",
    "    metrics['edge_blurry'] = edge_strength(blur_norm)\n",
    "    metrics['edge_deconvolved'] = edge_strength(deconv_norm)\n",
    "    metrics['edge_recovery_pct'] = (metrics['edge_deconvolved'] / metrics['edge_original']) * 100\n",
    "    \n",
    "    # === Residual Analysis ===\n",
    "    metrics['residual_blurry_mean'] = np.mean(np.abs(orig_norm - blur_norm))\n",
    "    metrics['residual_deconvolved_mean'] = np.mean(np.abs(orig_norm - deconv_norm))\n",
    "    metrics['residual_blurry_std'] = np.std(orig_norm - blur_norm)\n",
    "    metrics['residual_deconvolved_std'] = np.std(orig_norm - deconv_norm)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"=\" * 70)\n",
    "    print(\"RICHARDSON-LUCY DECONVOLUTION PERFORMANCE ANALYSIS\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    print(\"\\nüìä IMAGE QUALITY METRICS\")\n",
    "    print(\"-\" * 70)\n",
    "    print(f\"{'Metric':<25} {'Blurry':<15} {'Deconvolved':<15} {'Gain/Change':<15}\")\n",
    "    print(\"-\" * 70)\n",
    "    print(f\"{'PSNR (dB)':<25} {metrics['psnr_blurry']:>14.2f} {metrics['psnr_deconvolved']:>14.2f} {metrics['psnr_gain']:>+14.2f}\")\n",
    "    print(f\"{'SSIM':<25} {metrics['ssim_blurry']:>14.4f} {metrics['ssim_deconvolved']:>14.4f} {metrics['ssim_gain']:>+14.4f}\")\n",
    "    print(f\"{'MSE':<25} {metrics['mse_blurry']:>14.6f} {metrics['mse_deconvolved']:>14.6f} {metrics['mse_reduction_pct']:>+13.2f}%\")\n",
    "    print(f\"{'MAE':<25} {metrics['mae_blurry']:>14.6f} {metrics['mae_deconvolved']:>14.6f}\")\n",
    "    print(f\"{'Correlation':<25} {metrics['corr_blurry']:>14.4f} {metrics['corr_deconvolved']:>14.4f}\")\n",
    "    \n",
    "    print(\"\\nüîç SHARPNESS & EDGE METRICS\")\n",
    "    print(\"-\" * 70)\n",
    "    print(f\"{'Laplacian Variance':<25} {metrics['sharpness_blurry']:>14.6f} {metrics['sharpness_deconvolved']:>14.6f} ({metrics['sharpness_recovery_pct']:>6.1f}% of orig)\")\n",
    "    print(f\"{'Edge Strength':<25} {metrics['edge_blurry']:>14.6f} {metrics['edge_deconvolved']:>14.6f} ({metrics['edge_recovery_pct']:>6.1f}% of orig)\")\n",
    "    print(f\"{'Original Sharpness':<25} {metrics['sharpness_original']:>14.6f}\")\n",
    "    print(f\"{'Original Edge Strength':<25} {metrics['edge_original']:>14.6f}\")\n",
    "    \n",
    "    print(\"\\nüìâ RESIDUAL ANALYSIS\")\n",
    "    print(\"-\" * 70)\n",
    "    print(f\"{'Residual Mean':<25} {metrics['residual_blurry_mean']:>14.6f} {metrics['residual_deconvolved_mean']:>14.6f}\")\n",
    "    print(f\"{'Residual Std Dev':<25} {metrics['residual_blurry_std']:>14.6f} {metrics['residual_deconvolved_std']:>14.6f}\")\n",
    "    \n",
    "    print(\"\\n‚ú® SUMMARY\")\n",
    "    print(\"-\" * 70)\n",
    "    if metrics['psnr_gain'] > 3:\n",
    "        quality = \"Excellent\"\n",
    "    elif metrics['psnr_gain'] > 1:\n",
    "        quality = \"Good\"\n",
    "    elif metrics['psnr_gain'] > 0:\n",
    "        quality = \"Moderate\"\n",
    "    else:\n",
    "        quality = \"Poor (no improvement)\"\n",
    "    print(f\"Overall Quality Improvement: {quality}\")\n",
    "    print(f\"PSNR Gain: {metrics['psnr_gain']:.2f} dB\")\n",
    "    print(f\"SSIM Gain: {metrics['ssim_gain']:.4f}\")\n",
    "    print(f\"MSE Reduction: {metrics['mse_reduction_pct']:.1f}%\")\n",
    "    print(f\"Sharpness Recovery: {metrics['sharpness_recovery_pct']:.1f}%\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Visualization\n",
    "    create_performance_visualization(original, blurry, deconvolved, metrics, psf)\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "def create_performance_visualization(original, blurry, deconvolved, metrics, psf=None):\n",
    "    \"\"\"Create comprehensive visualization of results\"\"\"\n",
    "    \n",
    "    def scale_image(img, percentile=99.5):\n",
    "        vmin = np.percentile(img, 100 - percentile)\n",
    "        vmax = np.percentile(img, percentile)\n",
    "        return vmin, vmax\n",
    "    \n",
    "    def normalize(img):\n",
    "        img_min, img_max = img.min(), img.max()\n",
    "        if img_max == img_min:\n",
    "            return np.zeros_like(img)\n",
    "        return (img - img_min) / (img_max - img_min)\n",
    "    \n",
    "    orig_norm = normalize(original)\n",
    "    blur_norm = normalize(blurry)\n",
    "    deconv_norm = normalize(deconvolved)\n",
    "    \n",
    "    # Create figure\n",
    "    if psf is not None:\n",
    "        fig = plt.figure(figsize=(20, 12))\n",
    "        gs = fig.add_gridspec(3, 4, hspace=0.3, wspace=0.3)\n",
    "    else:\n",
    "        fig = plt.figure(figsize=(20, 10))\n",
    "        gs = fig.add_gridspec(2, 4, hspace=0.3, wspace=0.3)\n",
    "    \n",
    "    # Row 1: Images\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    vmin, vmax = scale_image(original)\n",
    "    ax1.imshow(original, cmap='gray', vmin=vmin, vmax=vmax)\n",
    "    ax1.set_title(\"Original (Ground Truth)\", fontsize=12, fontweight='bold')\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    vmin, vmax = scale_image(blurry)\n",
    "    ax2.imshow(blurry, cmap='gray', vmin=vmin, vmax=vmax)\n",
    "    ax2.set_title(f\"Blurry\\nPSNR: {metrics['psnr_blurry']:.2f} dB\", fontsize=12)\n",
    "    ax2.axis('off')\n",
    "    \n",
    "    ax3 = fig.add_subplot(gs[0, 2])\n",
    "    vmin, vmax = scale_image(deconvolved)\n",
    "    ax3.imshow(deconvolved, cmap='gray', vmin=vmin, vmax=vmax)\n",
    "    ax3.set_title(f\"Deconvolved (RL)\\nPSNR: {metrics['psnr_deconvolved']:.2f} dB\", fontsize=12)\n",
    "    ax3.axis('off')\n",
    "    \n",
    "    # Error maps\n",
    "    ax4 = fig.add_subplot(gs[0, 3])\n",
    "    error_map = np.abs(orig_norm - deconv_norm)\n",
    "    im = ax4.imshow(error_map, cmap='hot')\n",
    "    ax4.set_title(f\"Absolute Error Map\\nMean: {metrics['residual_deconvolved_mean']:.4f}\", fontsize=12)\n",
    "    ax4.axis('off')\n",
    "    plt.colorbar(im, ax=ax4, fraction=0.046)\n",
    "    \n",
    "    # Row 2: Difference images\n",
    "    ax5 = fig.add_subplot(gs[1, 0])\n",
    "    diff_blurry = orig_norm - blur_norm\n",
    "    ax5.imshow(diff_blurry, cmap='RdBu_r', vmin=-0.5, vmax=0.5)\n",
    "    ax5.set_title(\"Difference: Original - Blurry\", fontsize=12)\n",
    "    ax5.axis('off')\n",
    "    \n",
    "    ax6 = fig.add_subplot(gs[1, 1])\n",
    "    diff_deconv = orig_norm - deconv_norm\n",
    "    ax6.imshow(diff_deconv, cmap='RdBu_r', vmin=-0.5, vmax=0.5)\n",
    "    ax6.set_title(\"Difference: Original - Deconvolved\", fontsize=12)\n",
    "    ax6.axis('off')\n",
    "    \n",
    "    # Metrics comparison\n",
    "    ax7 = fig.add_subplot(gs[1, 2])\n",
    "    categories = ['PSNR\\n(normalized)', 'SSIM', 'Correlation']\n",
    "    blurry_vals = [\n",
    "        metrics['psnr_blurry'] / 50,  # Normalize to ~0-1\n",
    "        metrics['ssim_blurry'],\n",
    "        metrics['corr_blurry']\n",
    "    ]\n",
    "    deconv_vals = [\n",
    "        metrics['psnr_deconvolved'] / 50,\n",
    "        metrics['ssim_deconvolved'],\n",
    "        metrics['corr_deconvolved']\n",
    "    ]\n",
    "    \n",
    "    x = np.arange(len(categories))\n",
    "    width = 0.35\n",
    "    ax7.bar(x - width/2, blurry_vals, width, label='Blurry', alpha=0.8)\n",
    "    ax7.bar(x + width/2, deconv_vals, width, label='Deconvolved', alpha=0.8)\n",
    "    ax7.set_ylabel('Score', fontsize=10)\n",
    "    ax7.set_title('Quality Metrics Comparison', fontsize=12, fontweight='bold')\n",
    "    ax7.set_xticks(x)\n",
    "    ax7.set_xticklabels(categories, fontsize=9)\n",
    "    ax7.legend()\n",
    "    ax7.grid(axis='y', alpha=0.3)\n",
    "    ax7.set_ylim([0, 1.1])\n",
    "    \n",
    "    # Histogram comparison\n",
    "    ax8 = fig.add_subplot(gs[1, 3])\n",
    "    ax8.hist(orig_norm.flatten(), bins=50, alpha=0.5, label='Original', density=True)\n",
    "    ax8.hist(blur_norm.flatten(), bins=50, alpha=0.5, label='Blurry', density=True)\n",
    "    ax8.hist(deconv_norm.flatten(), bins=50, alpha=0.5, label='Deconvolved', density=True)\n",
    "    ax8.set_xlabel('Pixel Intensity', fontsize=10)\n",
    "    ax8.set_ylabel('Density', fontsize=10)\n",
    "    ax8.set_title('Intensity Distribution', fontsize=12, fontweight='bold')\n",
    "    ax8.legend()\n",
    "    ax8.grid(alpha=0.3)\n",
    "    \n",
    "    # Row 3: PSF and additional analysis (if PSF provided)\n",
    "    if psf is not None:\n",
    "        ax9 = fig.add_subplot(gs[2, 0])\n",
    "        ax9.imshow(psf, cmap='gray')\n",
    "        ax9.set_title(\"Point Spread Function (PSF)\", fontsize=12, fontweight='bold')\n",
    "        ax9.axis('off')\n",
    "        \n",
    "        # Cross-section comparison\n",
    "        ax10 = fig.add_subplot(gs[2, 1:3])\n",
    "        mid_row = original.shape[0] // 2\n",
    "        ax10.plot(orig_norm[mid_row, :], label='Original', linewidth=2, alpha=0.8)\n",
    "        ax10.plot(blur_norm[mid_row, :], label='Blurry', linewidth=2, alpha=0.8)\n",
    "        ax10.plot(deconv_norm[mid_row, :], label='Deconvolved', linewidth=2, alpha=0.8)\n",
    "        ax10.set_xlabel('Pixel Position', fontsize=10)\n",
    "        ax10.set_ylabel('Intensity', fontsize=10)\n",
    "        ax10.set_title(f'Cross-section (Row {mid_row})', fontsize=12, fontweight='bold')\n",
    "        ax10.legend()\n",
    "        ax10.grid(alpha=0.3)\n",
    "        \n",
    "        # Summary text\n",
    "        ax11 = fig.add_subplot(gs[2, 3])\n",
    "        ax11.axis('off')\n",
    "        summary_text = f\"\"\"\n",
    "PERFORMANCE SUMMARY\n",
    "{'='*30}\n",
    "\n",
    "PSNR Gain: {metrics['psnr_gain']:.2f} dB\n",
    "SSIM Gain: {metrics['ssim_gain']:.4f}\n",
    "MSE Reduction: {metrics['mse_reduction_pct']:.1f}%\n",
    "\n",
    "Sharpness Recovery:\n",
    "{metrics['sharpness_recovery_pct']:.1f}% of original\n",
    "\n",
    "Edge Recovery:\n",
    "{metrics['edge_recovery_pct']:.1f}% of original\n",
    "\n",
    "{'='*30}\n",
    "        \"\"\"\n",
    "        ax11.text(0.1, 0.5, summary_text, fontsize=10, family='monospace',\n",
    "                 verticalalignment='center', bbox=dict(boxstyle='round', \n",
    "                 facecolor='wheat', alpha=0.5))\n",
    "    \n",
    "    plt.suptitle('Richardson-Lucy Deconvolution Performance Analysis', \n",
    "                 fontsize=16, fontweight='bold', y=0.98)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Usage with your variables:\n",
    "# metrics = comprehensive_deconvolution_analysis(original_sharp, blurry_bs, rl, psf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bagpipes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
